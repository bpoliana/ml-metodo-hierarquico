{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificação Automática do Gênero do Filme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver o dataset e gerar o dataset de treino primeiro nivel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_songs = pd.read_csv(\"datasets/music.csv\")\n",
    "\n",
    "colunas_features_class = [f\"feature_{i+1}\" for i in range(17)]\n",
    "colunas_features_class.append(\"index\")\n",
    "colunas_features_class.append(\"genre\")\n",
    "colunas_features_class.append(\"original_genre\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dataset = df_songs[colunas_features_class]\n",
    "df_dataset = df_dataset[colunas_features_class]\n",
    "df_dataset.set_index(\"index\").iloc[[1, 6, 20, 26, 32, 44, 50, 52, 59, 93]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_prim_nivel = \"genre\"\n",
    "col_seg_nivel = \"original_genre\"\n",
    "\n",
    "arr_pos = []\n",
    "for pos,value_genre in enumerate(df_dataset[col_prim_nivel]):\n",
    "    if value_genre == \"Rock\":\n",
    "        arr_pos.append(pos)\n",
    "arr_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_prim_nivel = \"genre\"\n",
    "col_seg_nivel = \"original_genre\"\n",
    "\n",
    "df_filtrado = df_dataset[df_dataset[col_prim_nivel] == \"Indie\"]\n",
    "len(df_filtrado[col_seg_nivel].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs.set_index(\"index\")\n",
    "df_dataset_nivel_2 = df_songs[colunas_features_class_nivel_2]\n",
    "df_dataset_nivel_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nivel 1  - prever genre]\n",
    "     genre  original\n",
    "Treino \n",
    "1 - [Jazz] - Jazz\n",
    "2 - [Jazz] - R&B\n",
    "3 - [Rock] - Metal\n",
    "4 - [Rock] - Rock \n",
    "Teste: \n",
    "\n",
    "5 - Jazz - R&B  [Jazz]\n",
    "6 - Rock - Metal [Rock]\n",
    "7 - Rock - Rock [Jazz]\n",
    "8 - Jazz - R&B  [Rock]\n",
    "\n",
    "[nivel 2  prver original]\n",
    "Agrupamento de Rock: distinguir entre Rock e metal\n",
    "Treino: \n",
    "3 - Rock - [Metal]\n",
    "4 - Rock - [Rock]\n",
    "Teste:\n",
    "6 - Rock - Metal [Rock]\n",
    "8 - Jazz - R&B  [Rock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeamento geral: {0: 'Country', 1: 'Hip-Hop', 2: 'Indie', 3: 'Pop', 4: 'Jazz', 5: 'Metal', 6: 'Rock', 7: 'Folk', 8: 'Electronic', 9: 'R&B'}\n",
      "{0: 'Country', 1: 'Hip-Hop', 2: 'Indie', 3: 'Pop', 4: 'Jazz', 5: 'Rock'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/profhasan/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Primeiro nivel: [5 5 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1]\n",
      "Agrupamento: Country\n",
      "{0: 'Country', 1: 'Folk'}\n",
      "y treino: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1] to predict: [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/profhasan/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predições: [1 1 0]\n",
      "Posicao 0 correspond a posicao 7\n",
      "Posicao 1 correspond a posicao 12\n",
      "Posicao 2 correspond a posicao 16\n",
      "Agrupamento: Hip-Hop\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "13\n",
      "14\n",
      "15\n",
      "17\n",
      "18\n",
      "19\n",
      "Agrupamento: Indie\n",
      "Agrupamento: Pop\n",
      "Agrupamento: Jazz\n",
      "Agrupamento: Rock\n",
      "{0: 'Metal', 1: 'Rock', 2: 'Country', 3: 'Pop'}\n",
      "y treino: [0, 1, 1, 1, 1, 0] to predict: [2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/profhasan/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predições: [0 0]\n",
      "Posicao 0 correspond a posicao 0\n",
      "Posicao 1 correspond a posicao 1\n"
     ]
    }
   ],
   "source": [
    "from base_am.resultado import Fold\n",
    "from base_am.avaliacao import Experimento\n",
    "from competicao_am.metodo_competicao import MetodoHierarquico\n",
    "from competicao_am.avaliacao_competicao import OtimizacaoObjetivoSVMCompeticao\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/music.csv\")\n",
    "\n",
    "\n",
    "colunas_features_class = [f\"feature_{i+1}\" for i in range(17)]\n",
    "colunas_features_class.append(\"index\")\n",
    "colunas_features_class.append(\"genre\")\n",
    "colunas_features_class.append(\"original_genre\")\n",
    "\n",
    "df_amostra = df_amostra[colunas_features_class]\n",
    "\n",
    "arr_folds = Fold.gerar_k_folds(df_amostra, val_k=5, col_classe=\"original_genre\",\n",
    "                            num_repeticoes=1, num_folds_validacao=4,num_repeticoes_validacao=1)\n",
    "\n",
    "scikit_method = LinearSVC(random_state=2)\n",
    "ml_method = MetodoHierarquico(scikit_method, \"genre\")\n",
    "\n",
    "arr_to_predict, arr_predictions = ml_method.eval(arr_folds[0].df_treino, arr_folds[0].df_data_to_predict, \"original_genre\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 7, 1, 1, 1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>index</th>\n",
       "      <th>genre</th>\n",
       "      <th>original_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.732824</td>\n",
       "      <td>1.091603</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>131.0</td>\n",
       "      <td>372672</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224705</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.635556</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>225.0</td>\n",
       "      <td>31855</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.015732</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.015732</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>29571</td>\n",
       "      <td>Country</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.711111</td>\n",
       "      <td>1.059259</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1801</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>310261</td>\n",
       "      <td>Country</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "36   0.732824   1.091603   0.671329   0.115385      131.0     372672   \n",
       "56   0.426667   0.635556   0.671329   0.111111      225.0      31855   \n",
       "31   0.711111   1.059259   0.671329   0.150000      135.0       1801   \n",
       "\n",
       "    feature_7  feature_8  feature_9  feature_10  feature_11  feature_12  \\\n",
       "36   0.285714   0.007463   0.006110    0.011940    0.011940    0.007463   \n",
       "56   0.428571   0.011940   0.015732    0.022388    0.022388    0.011940   \n",
       "31   0.800000   0.008955   0.010950    0.017910    0.017910    0.008955   \n",
       "\n",
       "    feature_13  feature_14  feature_15  feature_16  feature_17   index  \\\n",
       "36    0.006110    0.011940    0.004478         1.0         0.0  224705   \n",
       "56    0.015732    0.022388    0.002985         0.6         0.4   29571   \n",
       "31    0.010950    0.017910    0.005970         0.5         0.5  310261   \n",
       "\n",
       "      genre original_genre  \n",
       "36     Jazz           Jazz  \n",
       "56  Country        Country  \n",
       "31  Country        Country  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_folds[0].df_data_to_predict.iloc[[6,12,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_folds[0].df_treino[\"original_genre\"].valu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ml_method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(random_state=2)\n",
    "ml_method = MetodoHierarquico(svm)\n",
    "ClasseObjetivo = OtimizacaoObjetivoSVMCompeticao\n",
    "\n",
    "#colocamos apenas 5 trials para ir mais rápido. Porém, algumas vezes precisamos de dezenas, centenas - ou milhares - de trials para conseguir uma boa configuração\n",
    "#Isso depende muito da caracteristica do problema, da quantidade de parametros e do impacto desses parametros no resultado\n",
    "experimento = Experimento(arr_folds, ml_method=ml_method,\n",
    "                    ClasseObjetivoOtimizacao=ClasseObjetivo,\n",
    "                    num_trials=100)\n",
    "resultado = experimento.calcula_resultados()\n",
    "print(f\"MACRO F1 fold 1: {resultado[0].macro_f1_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você recebeu este dataset e seu objetivo é estimar o genero dele (comédia ou ação) de acordo com seus atributos - contidos neste dataset.\n",
    "\n",
    "**O que você deverá fazer?**\n",
    "\n",
    "- Explorar e entender os dados\n",
    "- Criar os atributos de treino para isso, voce deverá:\n",
    "    - Verificar a existencia de valores ausentes e verificar estratégias para lidar com eles\n",
    "    - Descobrir a melhor forma de representar valores categóricos e textual (veja explicação abaixo) \n",
    "- Avaliar e descobrir o melhor método podendo considerar:\n",
    "     - Qual são os melhores parametros?\n",
    "     - Quais são os melhores métodos?\n",
    "     - A combinação de mais de um método é útil?\n",
    "     - Qual é a melhor representação de uma instancia? Ou seja, qual é a melhor forma de preprocessar meus atributos? Fazer normalização dos atributos auxiliará? Como lidar com dados inexistentes? \n",
    "     - Pode-se criar modelos de representações diferentes e combiná-los (Multiview)\n",
    "     - Como lidar com um dataset que possui muito mais instancias de uma classe que outra? Isso pode fazer com que alguns métodos ficam tendenciosos para a classe que possui mais elementos.  Uma estratégia é usar undersampling: caso tenhamos uma classe com 10.000 e outra com 5.000, utilize uma amostra de 5.000 instancias da primeira classe para o treinamento.\n",
    "     \n",
    "Lembrem-se: temos pouco tempo, então, faça de um jeito simples, veja e investigue os erros e, logo após, vá incrementando..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O que será entregue**\n",
    "\n",
    "Após descoberto o melhor modelo, você receberá [um dataset como esse](datasets/movies_amostra_teste_ex.csv) - sem a informação sobre genero - e você deverá prever qual será o genero do film. Após avaliar vários modelos e descobrir o melhor, você entregará seu código zipado junto com a predição por instancia em um arquivo de nome `predict.txt` no seguinte formato: Para cada linha o exemplo de teste, o valor `comedy` ou `action` definindo seu genero. Por exemplo, caso tenhamos um dataset de teste de 10 instancias, uma possível saída seria: \n",
    "\n",
    "```\n",
    "comedy\n",
    "comedy\n",
    "action\n",
    "action\n",
    "action\n",
    "comedy\n",
    "comedy\n",
    "action\n",
    "comedy\n",
    "action\n",
    "```\n",
    "\n",
    "O professor terá as saídas esperadas do teste e irá compará-lo a partir da saída gerada. Caso o arquivo não tenha esse nome ou esteja fora do padrão, o resultado da equipe será desconsiderado. **Haverá duas rodadas e, cada rodada, um dataset de teste diferente**.\n",
    "\n",
    "\n",
    "Para facilitar a reprodutibilidade, a implementação do modelo deverá estar bem organizada seguindo as seguintes especificações: \n",
    "\n",
    "- O modelo a ser gerado deverá ser subclasse de `MetodoAprendizado`. Nessa subclasse, você poderá facilmente criar um metodo com multiplos métodos de aprendizado de máquina e/ou também, para diferentes representações você pode passar como parametro no construtor as colunas do dataframe de cada visão. Por exemplo, caso tenhamos em uma visão os atributos `a'`, `b`, `c` e, em outro os atributos `x`, `y` e `z`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visao_1 = ['a','b','c']\n",
    "visao_2 = ['x','y','z']\n",
    "# o código não irá executar pois não implementamos essa classe ainda\n",
    "metodo = MetodoCompeticao([ visao_1, visao_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, no método `eval` você deverá apenas filtrar o dataframe por visão e gerar um vetor de predição por visão para, logo após, combiná-lo por maioria de votos, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regras** \n",
    "\n",
    "- O conhecimento e geração dos atributos/preprocessamente e método deve vir apenas no dataset `movies_amostra.csv`. Por exemplo, não é permitido adicionar um valor faltante a um filme baseado no seu conhecimento sobre o mesmo - ou de outros dados da Internet. A unica exceção a essa regra é o uso de palavras-chaves (que podem ser criadas por vocẽ) para geração de atributos (detalhado nas seções a seguir).\n",
    "\n",
    "- Da mesma forma, o treino deve ser criado usando **apenas** as instancias do arquivo `movies_amostra.csv`. Por exemplo, o teste `movies_amostra_teste_ex.csv` não pode ser usado para criar dados de treino e nem outros dados fornecidos pelo professor ou externo. \n",
    "\n",
    "- Não é permitido salvar o objeto em arquivo (usando pickle, por exemplo) para ser lido na função `gerar_saidas_teste`\n",
    "\n",
    "- O teste deve ser reprodutível, ou seja, resultado dos experimentos do código executado no computador do professor deve ter o mesmo resultado daquele obtido pelos alunos. \n",
    "\n",
    "- A organização dos arquivos deve ser respeitada, além do formato do `predict_grupoXX.txt`.\n",
    "\n",
    "- O arquivo de saída deve ser exatamente o nome `predict_grupoXX.txt` sendo que XX é substituido pelo número do grupo e o formato conforme especificado. \n",
    "\n",
    "- Equipe que não enviar nada na primeira rodada poderá enviar na segunda rodada. \n",
    "\n",
    "Caso a equipe não siga essas regras, ela será desclassificada. Caso haja algum problema, a equipe deve comunicar ao professor no chat do Discord.\n",
    "\n",
    "**Duvidas: ** Todas as dúvidas devem ser postadas no canal `#competicao`. Para não beneficiar uma equipe ou outra, as dúvidas não serão esclarecidas no privado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organização dos arquivos: **\n",
    "\n",
    "- Os arquivos `metodo.py`, `resultado.py` e `avaliacao.py` na pasta `base_am` devem permanecer sem modificações\n",
    "\n",
    "- Qualquer método de aprendizado de maquina usado deverá estar no arquivo `metodo_competicao.py` na pasta `competicao_am` e ser subclasse de `MetodoAprendizadoMaquina` - já existe um exemplo pronto.\n",
    "    \n",
    "- Qualquer modificação da  avaliação experimental deve estar em `avaliacao_competicao.py` na pasta `competicao_am`. Alteração do experimento deve ser subclasse de `Experimento` e a as classes para variação dos parametros devem ser subclasses de `OtimizacaoObjetivo` e estar nesse mesmo arquivo. Há um exemplo de implementação da classe `OtimizacaoObjetivo` nesse arquivo.\n",
    "\n",
    "- Caso seja necessária alguma modificação em classes do `resultado.py`, você deve fazer um arquivo `resultado_competicao.py` fazendo subclasses/associações das classes especificadas em `resultado.py`\n",
    "    \n",
    "- `preprocessamento_atributos_competicao.py`: Usará o arquivo `preprocessamento_atributos`  (se necessário) e criará os atributos do modelo. Você pode também criar as classes que desejar para criação dos atributos nesse arquivo. \n",
    "- Arquivo `gerar_resultado_teste.py` na pasta `competicao_am` que você deverá apresentar o código para gerar a saída para o dataset fornecido pelo professor. Esse código deverá usar o arquivo `datasets/movies_amostra.csv` para treino - nenhum outro arquivo a mais, fazer todo o processamento necessario, criação do modelo e gerar a saída. A função principal que gera a saída deve ser obrigatoriamente `gerar_saida_teste` - já com um exemplo implementado. Esse código deve estar claro e que seja possível o professor reproduzir o mesmo resultado. Há um exemplo pronto também. \n",
    "\n",
    "- Haverá `competicao.ipynb` explicando qual foi a solução adotada passo a passo: (a) como se escolheu o conjuntos de parametros? (c) qual foi a representação adotada?  (d) Como vocẽs chegaram nesta representação? ;(d) quais métodos foram adotados? (e) deixar claro passo a passo a implementação da função `gerar_saida_teste`do arquivo `gerar_resultado_teste.py`. Nesse arquivo Jupyter não haverá muito código apenas, se necessário, chamada as funções/métodos dos arquivos `.py` acima. Durante a competição, vocês testarão diversas representações e modelos. Porém, neste arquivo, você deverá usar apenas a representação e modelo que você considerou mais efetivo. Coloque também um paragrafo explicando o caminho e tentativas que não deram tanto certo. Além disso, nesse arquivo você deverá   Caso tenha sido feito uso de palavras chaves, lista-las e explicar como chegou nas mesmas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dinamica da competição**\n",
    "\n",
    "Haverá 2 rodadas, cada rodada terá 3 fases: \n",
    "\n",
    "1. **Elaboração da solução e descoberta do melhor modelo**: nesta fase, você criará a solução que você julgar a melhor. Logo após, você enviará essa solução pronta no Moodle.\n",
    "2. **Geração do resultado no dataset fornecido pelo professor**: logo após a entrega, estará disponível um dataset de teste para você gerar a predição. Nessa fase, você deverá usar seu código (submetido na fase anterior) para prever o resultado desse dataset. Porém, você não poderá alterar nenhuma parte de seu código, pois ele já foi submetido. Por isso, não esqueça de [testar seu código com este dataset](teste_ex.csv). Logo após, você deverá enviar o seu resultado via Moodle - o prazo para envio será de apenas 1 dia após da entrega de sua solução. \n",
    "3. **Apresentação do resultado**: com os resultados de cada equipe, o professor irá apresentar o ranking de cada solução por equipe\n",
    "\n",
    "Os prazos não serão alterados devido ao atraso de alguma equipe. Instruções para implementação das fases 1 e 2 serão dadas a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critérios de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os códigos serão classificados de acordo com a macro F1. Caso ocorra empate, será feito desempate na seguinte ordem: \n",
    "\n",
    "1. F1 Score da classe `Action`\n",
    "2. Tempo de execução da função `gerar_saida_teste`\n",
    "3. Caso seja a segunda rodada, os critérios acima, nesta ordem, da primeira rodada\n",
    "4. Clareza do código e elegancia da solução\n",
    "\n",
    "O resultado final será o resultado da segunda rodada. Caso uma equipe entregue apenas a primeira rodada, será executado o método entregue na primeira rodada no dataset da segunda rodada para a classificação final. A  equipe pode participar da segunda rodada sem ter participado da primeira desde que tenha se inscrito na competição. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Dataset de treino e avaliação](datasets/movies_amostra.csv)\n",
    "- [Dataset de teste - exemplo](datasets/movies_amostra_teste_ex.csv)\n",
    "- [Dataset de teste - primeira rodada](datasets/movies_amostra_teste_1.csv): a ser disponibilizado pelo professor após a 2ª fase da primeira rodada\n",
    "- [Dataset de teste - segunda rodada](datasets/movies_amostra_teste_2.csv): a ser disponibilizado pelo professor após a 2ª fase da segunda rodada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de representações de dados categóricos e textual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria dos métodos de aprendizado de máquina esperam como entrada valores numéricos. Por isso, temos que fazer tratamento quando o dado é categorico. Além disso, outro tipo de dado que precisamos de tratamento especial é o texto corrido que pode trazer muita informação relevante para tarefas de aprendizado de máquin. Nesta seção, será explicado um pouco sobre algumas abordagens da mais simples até a mais usada\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação para um número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A forma mais simples de se fazer a transformação é simplesmente mapear esse atributo para um valor numérico. Veja o exemplo abaixo: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_jogos = pd.DataFrame([   [\"boa\",\"nublado\",\"não\"],\n",
    "                            [\"boa\",\"chuvoso\",\"não\"],\n",
    "                           [\"média\",\"nublado\",\"sim\"],\n",
    "                         [\"fraca\",\"chuvoso\",\"não\"]],\n",
    "                        columns=[\"disposição\",\"tempo\",\"jogar volei?\"])\n",
    "df_jogos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, temos dois atributos disposição do jogador e tempo e queremos prever se o jogar irá jogar volei ou não. Tanto os atributos quanto a classe podem ser mapeados como número. Além disso, o atributo `disposicao` é um atributo que representa uma escala - o que deixa essa forma de tranformação bem adequada para esse atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def mapeia_atributo_para_int(df_data:pd.DataFrame, coluna:str, dic_nom_to_int: Dict[int,str]):\n",
    "    for i,valor in enumerate(df_data[coluna]):\n",
    "        valor_int = dic_nom_to_int[valor]\n",
    "        df_data[coluna].iat[i] = valor_int\n",
    "\n",
    "        \n",
    "df_jogos = pd.DataFrame([   [\"boa\",\"nublado\",\"sim\"],\n",
    "                            [\"boa\",\"chuvoso\",\"não\"],\n",
    "                           [\"média\",\"ensolarado\",\"sim\"],\n",
    "                         [\"fraca\",\"chuvoso\",\"não\"]],\n",
    "                        columns=[\"disposição\",\"tempo\",\"jogar volei?\"])\n",
    "dic_disposicao = {\"boa\":3,\"média\":2,\"fraca\":1}\n",
    "mapeia_atributo_para_int(df_jogos, \"disposição\", dic_disposicao)\n",
    "\n",
    "dic_tempo = {\"ensolarado\":3,\"nublado\":2,\"chuvoso\":1}\n",
    "mapeia_atributo_para_int(df_jogos, \"tempo\", dic_tempo)\n",
    "\n",
    "dic_volei = {\"sim\":1, \"não\":0}\n",
    "mapeia_atributo_para_int(df_jogos, \"jogar volei?\", dic_volei)\n",
    "df_jogos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarização dos atributos categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Podemos fazer a binarização dos atributos categóricos em que, cada valor de atributo transforma-se em uma coluna que recebe `0` caso esse atributo não exista e `1`, caso contrário. Em nosso exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessamento_atributos import BagOfItems\n",
    "df_jogos = pd.DataFrame([   [4, \"boa\",\"nublado\",\"sim\"],\n",
    "                            [3,\"boa\",\"chuvoso\",\"não\"],\n",
    "                           [2,\"média\",\"ensolarado\",\"sim\"],\n",
    "                         [1,\"fraca\",\"chuvoso\",\"não\"]],\n",
    "                        columns=[\"id\",\"disposição\",\"tempo\",\"jogar volei?\"])\n",
    "dic_disposicao = {\"boa\":3,\"média\":2,\"fraca\":1}\n",
    "\n",
    "\n",
    "bag_of_tempo = BagOfItems(0)\n",
    "#veja a implementação do método em preprocesamento_atributos.py\n",
    "df_jogos_bot = bag_of_tempo.cria_bag_of_items(df_jogos,[\"tempo\"])\n",
    "df_jogos_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como existem vários valores no teste que você desconhece, se fizermos dessa forma, atributos que estão no teste poderiam estar completamente zerados no treino, sendo desnecessário, por exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_treino = df_jogos[:2]\n",
    "df_jogos_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_teste = df_jogos[2:]\n",
    "df_jogos_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, o tempo ensolarado não está no treino e, assim, não haveria esse atributo no treinamento. Assim, a forma mais correta de fazermos é (a) descobrirmos a lista de valores no treino e, logo após, aplicamos ela no teste. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_tempo = BagOfItems(0)\n",
    "df_jogos_bot_treino = bag_of_tempo.cria_bag_of_items(df_jogos_treino,[\"tempo\"])\n",
    "df_jogos_bot_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_bot_teste = bag_of_tempo.aplica_bag_of_items(df_jogos_teste,[\"tempo\"])\n",
    "df_jogos_bot_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o impacto no resultado não é tão grande, muitas vezes optamos por fazer binarização no dataset completo, por simplicidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como veremos no próximo exemplo, a binarização pode gerar milhares de atributos pois, em um exemplo completo, uma coluna pode assumir muitos valores. Por isso, colocamos um dataframe separado com tais colunas - neste caso, o `df_jogos_bot`. Se desejar, você pode juntar dois DataFrames pelo `id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_full = pd.merge(df_jogos, df_jogos_bot, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso exemplo, as colunas que representam os atores principais podem ser binarizadas. Abaixo, veja um sugestão de como fazer em dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso caso, podemos colocar os atores todos em um \"Bag of Items\". Os atores são representados por as colunas `ator_1`, `ator_2`,..., `ator_5`. Podemos fazer da forma mais simples, que é usando o dataset todo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessamento_atributos import BagOfItems\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/movies_amostra.csv\")\n",
    "\n",
    "\n",
    "obj_bag_of_actors = BagOfItems(min_occur=3)\n",
    "\n",
    "#boa=bag of actors ;)\n",
    "df_amostra_boa = obj_bag_of_actors.cria_bag_of_items(df_amostra,[\"ator_1\",\"ator_2\",\"ator_3\",\"ator_4\",\"ator_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amostra_boa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que temos bastante atributos um para cada ator. Mesmo sendo melhor possuirmos poucos atributos e mais informativos, um método de aprendizado de máquina pode ser capaz de usar essa quantidade de forma eficaz. Particularmente, o [SVM linear](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) e o [RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) são métodos que conseguem ir bem nesse tipo de dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo após, pode-se juntar os dados dos atores com os demais: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_final = pd.merge(df_amostra, df_amostra_boa, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é a forma mais prática de fazer, porém, conforme já mencionado, alguns atributos seriam inúteis para o teste. Isso pode fazer com que o resultado reproduza menos o mundo real - neste caso, é muito possível que a diferença seja quase insignificante. Mas, caso queiramos fazer da forma \"mais correta\", temos que considerar apenas o treino para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supondo que 80% da amostra é treino\n",
    "df_treino_amostra = df_amostra.sample(frac=0.8, random_state = 2)\n",
    "df_teste_amostra = df_amostra.drop(df_teste_amostra.index)\n",
    "#min_occur=3 definie o minimo de ocorrencias desse ator para ser considerado\n",
    "#pois, um ator que apareceu em poucos filmes, pode ser menos relevante para a predição do genero\n",
    "obj_bag_of_actors = BagOfItems(min_occur=3)\n",
    "df_treino_amostra_boa = obj_bag_of_actors.cria_bag_of_items(df_treino_amostra,[\"ator_1\",\"ator_2\",\"ator_3\",\"ator_4\",\"ator_5\"])\n",
    "df_teste_amostra_boa = obj_bag_of_actors.aplica_bag_of_items(df_teste_amostra,[\"ator_1\",\"ator_2\",\"ator_3\",\"ator_4\",\"ator_5\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from base_am.resultado import Fold\n",
    "from base_am.avaliacao import Experimento\n",
    "from competicao_am.metodo_competicao import MetodoCompeticao\n",
    "from competicao_am.avaliacao_competicao import OtimizacaoObjetivoSVMCompeticao, OtimizacaoObjetivoRandomForest\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/movies_amostra.csv\")\n",
    "\n",
    "arr_folds = Fold.gerar_k_folds(df_amostra, val_k=5, col_classe=\"genero\",\n",
    "                            num_repeticoes=1, num_folds_validacao=4,num_repeticoes_validacao=1)\n",
    "scikit_method = LinearSVC(random_state=2)\n",
    "\n",
    "\n",
    "ml_method = MetodoCompeticao(scikit_method)\n",
    "\n",
    "ClasseObjetivo = OtimizacaoObjetivoSVMCompeticao\n",
    "#colocamos apenas 5 trials para ir mais rápido. Porém, algumas vezes precisamos de dezenas, centenas - ou milhares - de trials para conseguir uma boa configuração\n",
    "#Isso depende muito da caracteristica do problema, da quantidade de parametros e do impacto desses parametros no resultado\n",
    "experimento = Experimento(arr_folds, ml_method=ml_method,\n",
    "                    ClasseObjetivoOtimizacao=ClasseObjetivo,\n",
    "                    num_trials=2)\n",
    "print(f\"MACRO F1: {experimento.macro_f1_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas vezes, temos textos que podem ser relevantes para uma determinada tarefa de aprendizado d máquina. Por isso, temos que representar tais elementos para nosso método de aprendizado de máquina. \n",
    "\n",
    "A forma mais usual para isso, é a `Bag of Words` em que cada palavra é um atributo e, o valor dela, é a frequencia dele no texto (ou algum outro valor que indique a importancia dessa palavra no texto).\n",
    "\n",
    "Por exemplo, caso temos as frases `A casa é grande`, `A casa é verde verde` em que cada frase é uma instancia diferente. A representação seria da seguinte forma: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bow = {\"a\":[1,1],\n",
    "         \"casa\":[1,1],\n",
    "         \"é\":[1,1],\n",
    "         \"verde\":[0,2]\n",
    "        }\n",
    "df_bow = pd.DataFrame.from_dict(dic_bow)\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da forma que fizemos acima, usamos a frequencia de um termo para definir sua importancia no texto, porém, existem termos que possuem uma frequencia muito alta e importancia baixa: são os casos dos artigos e preposições por exemplo, pois, eles não discriminam o texto. \n",
    "\n",
    "Uma forma de mensurar o porder discriminativo das palavras é usando a métrica `TF-IDF`. Para calcularmos essa métrica, primeiramente calculamos a frequencia de um termo no documento (TF) e, logo após multiplamos pelo IDF. \n",
    "A fórmula para calcular o TF-IDF do termo $i$ no documento (ou instancia) $j$ é a seguinte:\n",
    "\n",
    "\\begin{equation}\n",
    "    TFIDF_{ij} = TF_{ij} \\times IDF_i\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    TF_{ij} = log(f_{ij})\n",
    "\\end{equation}\n",
    "\n",
    "em que $f_{ij}$ é a frequencia de um termo $i$ no documento $j$. Usa-se o `log` para suavizar valores muito altos e o $IDF$ (do inglês, _Inverse Document Frequency_) do termo $i$ é calculado da seguinte forma:\n",
    "\n",
    "\\begin{equation}\n",
    "    IDF_i = log(\\frac{N}{n_i})\n",
    "\\end{equation}\n",
    "\n",
    "em que $N$ é o número de documentos da coleção e $n_i$ é o número de documentos em que esse termo $i$ ocorre. Espera-se que, quanto mais discriminativo o termo, em menos documentos esse termo irá ocorrer e, consequentemente, o $IDF$ deste termo será mais alto. \n",
    "\n",
    "Por exemplo, considere as palavras `de`, `bebida` e `cerveja`. `cerveja` é uma palavra mais discriminativa do que `bebida`; e `bebibda` é mais discriminativo do que a preposição `de`. Muito provavelmente teremos mais frequentemente termos menos discriminativos. Por exemplo, se tivermos uma coleção de 1000 documentos,   `de` poderia ocorrer em 900 documentos,  `bebida` em 500 e `cerveja` em 100 documentos. Se fizermos o calculo, veremos que quanto mais discriminativo um termo, mais alto é seu IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "N = 1000\n",
    "n_de = 900\n",
    "n_bebida = 500\n",
    "n_cerveja = 100\n",
    "\n",
    "IDF_de = math.log(N/n_de)\n",
    "IDF_bebida = math.log(N/n_bebida)\n",
    "IDF_cerveja = math.log(N/n_cerveja)\n",
    "\n",
    "print(f\"IDF_de: {IDF_de}\\tIDF_bebida:{IDF_bebida}\\tIDF_cerveja:{IDF_cerveja}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca `scikitlearn`também já possui uma classe [TFIDFVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) que transforma um texto em um vetor de atributos usando o TF-IDF para o valor referente a relevancia deste termo. Veja um exemplo na coluna `resumo` do nosso dataset de filme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>009</th>\n",
       "      <th>05pm</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>100th</th>\n",
       "      <th>...</th>\n",
       "      <th>śliwą</th>\n",
       "      <th>światłem</th>\n",
       "      <th>şehirlere</th>\n",
       "      <th>şimdi</th>\n",
       "      <th>şte</th>\n",
       "      <th>że</th>\n",
       "      <th>życie</th>\n",
       "      <th>życiowe</th>\n",
       "      <th>आव</th>\n",
       "      <th>गल</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 18732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  007  009  05pm   10  100  1000  1001  100th  ...  śliwą  \\\n",
       "0     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "1     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "2     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "3     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "4     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "...   ...  ...  ...  ...   ...  ...  ...   ...   ...    ...  ...    ...   \n",
       "2995  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "2996  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "2997  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "2998  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "2999  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...    0.0   \n",
       "\n",
       "      światłem  şehirlere  şimdi  şte   że  życie  życiowe   आव   गल  \n",
       "0          0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "1          0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "2          0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "3          0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "4          0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "...        ...        ...    ...  ...  ...    ...      ...  ...  ...  \n",
       "2995       0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "2996       0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "2997       0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "2998       0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "2999       0.0        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  \n",
       "\n",
       "[3000 rows x 18732 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from base_am.preprocessamento_atributos import BagOfWords\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/movies_amostra.csv\")\n",
    "bow_amostra = BagOfWords()\n",
    "df_bow_amostra = bow_amostra.cria_bow(df_amostra,\"resumo\")\n",
    "df_bow_amostra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de meetodo para avaliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_atributos_resumo(df_treino:pd.DataFrame, df_data_to_predict: pd.DataFrame) -> pd.DataFrame:\n",
    "    bow_amostra = BagOfWords()\n",
    "    df_bow_treino = bow_amostra.cria_bow(df_treino,\"resumo\")\n",
    "    df_bow_data_to_predict = bow_amostra.aplica_bow(df_data_to_predict,\"resumo\")\n",
    "\n",
    "    return df_bow_treino,df_bow_data_to_predict\n",
    "class Metodo:\n",
    "    def eval_bow(self, df_treino:pd.DataFrame, df_data_to_predict:pd.DataFrame, col_classe:str, seed:int=1):\n",
    "        #separação da classe \n",
    "        x_treino, x_to_predict = self.obtem_x(df_treino, df_data_to_predict, col_classe)\n",
    "        y_treino, y_to_predict = self.obtem_y(df_treino, df_data_to_predict, col_classe)\n",
    "        \n",
    "        #geração dos atributos por meio do df_treino e df_data_to_predict\n",
    "        df_treino_bow, df_to_predict_bow = gerar_atributos_resumo(x_treino, x_to_predict)\n",
    "\n",
    "        #treina e aplica os modelos de cada representação\n",
    "        #o meotod fit altera o proprio objeto `ml_method`, por isso, temos que fazer um fit e depois\n",
    "        # seu respectivo predict  \n",
    "        self.ml_method.fit(df_treino_bow, y_treino)\n",
    "        arr_predict = self.ml_method.predict(df_to_predict_bow)\n",
    "\n",
    "        #if y_to_predict:\n",
    "        #   print(classification_report(y_to_predict, arr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como são muitos atributos, pode parecer que não ficou corretamente gerado. Mas, filtrando as palavras de um determinado resumo você verificará que está ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow_amostra[[\"in\",\"lake\", \"high\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que também é uma representação muito extensa, com dezenas de milhares de atributos. Como a representação dos autores e dos resumos, dessa forma, ficou com muitos atributos uma sugestão é fazer modelos separados e combinar as suas predições. Você pode pensar em várias formas de combinação:\n",
    " \n",
    "- Usar três representações: dos atores, do resumo e dos demais dados, combiná-las usando votação por maioria\n",
    "\n",
    "- Verificar a  predição com maior probabilidade - usando o método [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não fique preso apenas nessas representações. Vocês podem tentar fazer representações mais sucintas, como, por exemplo: para preprocessar os dados da equipe do filme (atores, diretor e escritor), calcule o número de filmes de comédia que membros da equipe  participaram e, logo após, o número de filme de ação. Neste caso, como você usará a classe, você deverá usar **apenas** os dados de treino. No caso do resumo, você pode utilizar palavras chaves. Por exemplo, faça uma lista de palavras chaves que remetem \"ação\" e contabilize o quantidade dessas palavras chaves no resumo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como avaliar modelos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visando uma melhor organização do código e para que vocês possam ter a experiencia de adaptar códigos dos outros - com restrições - vocês deverão fazer as implementações apenas nos arquivos de final \"competição\" fazendo subclasses/associações com as classes presentes nos arquivos `avaliacao.py`, `resultado.py` e `metodo.py`. \n",
    "\n",
    "Em `metodo_competicao.py` e `avaliacao_competicao` fizemos um exemplo simples usando nosso BOW para vocês entenderem o que deve ser feito nessa tarefa. Em `metodo_competicao.py` fizemos um método exemplo nele, temos que preprocessar e gerar alguns atributos. Para isso, fizemos a chamada do método de preprocessamento dentro dele com funções implementadas em `preprocessamento_atributos_competicao.py`. Não houv necessidade, porém, você poderia criar novas classes de tipos diferentes de preprocessamento e geração de atributos além de poder criar subclasses de BagOfWords para fazer algum preprocessamento diferente dessas classes.\n",
    "\n",
    "De forma similar a prática de avaliação, você deve gerar experimentos, analisar e entende-los. Investigue quando su método é bom o ruim e, com isso, tente melhorá-lo. Para isso, analise vários tipos de representações, métodos e suas combinações além de parametros para descobrir qual é o melhor. Dentre analises interessantes, tente refletir qual a classe que o método erra mais, se em algum grupo de instancia que ocorreu erro há alguma particularidade - analisando, principalmente, seus atributos. Verifique também se está ocorrendo overfitting/underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ConvergenceWarning que você está vendo é por que o SVM, assim como vários métodos de aprendizado de máquina, tentam convergir para um determinado resultado e, por algum motivo, para uma das representações o SVM não está convergindo. Você pode aumentar o valor do parametro que regula isso ou até alterar a representação para deixá-la mais informativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que recomendo fazer: para descobrir a melhor representação e método, use diretamente a classe `MetodoCompeticao`  para ir brincando e descartando representações que aparentemente, não foram tão boas com os parametros padrão. Logo após, utilize as mais promissoras e analise o resultado. Sempre considere, além da macro-f1, a precisão e revocação por classe além da matriz de confusão. Use a classe `Experimento` para analisar o impacto dessas representações também considerando a melhor configuração de parametros. Se desejar, crie uma subclasse de `Experimento` em \"avaliacao_competicao.py\" para gerar algumas análises, por exemplo, gerar a matriz de confusão que agrupa o resultado dos folds. Para agregar as matrizes de confusão, você pode gerar tanto a média da quantidade por fold ou fazer o somatório de todas elas. \n",
    "\n",
    "Este foi um exemplo com apenas um modelo para as duas representações. Você poderia, para cada representação, criar modelos distintos e com parametros distintos. Para isso, você pode mudar o constutor da classe `MetodoCompeticao`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma boa prática é salvar seus experimentos em arquivos, com algum nome sugestivo. Assim, você não precisará rodar ele novamente para analisá-lo. Uma excelente e bem organizada forma é usar um banco de dados. Porém, você pode simplesmente salvar o objeto em um arquivo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#salva\n",
    "pickle.dump( experimento, open( \"resultados/exp_bow_e_bag_of_actors.p\", \"wb\" ) )\n",
    "#salvo\n",
    "experimento = pickle.load( open( \"resultados/exp_bow_e_bag_of_actors.p\", \"rb\" ) )\n",
    "print(f\"MACRO F1: {experimento.macro_f1_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração do resultado no dataset fornecido pelo professor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de definido a melhor solução, você deverá aplicá-la no teste fornecido pelo professor. Para esse teste você deverá usar a função `gerar_saida_teste` do arquivo `gerar_resultado_teste.py` criada por você na fase de elaboração da solução. Nele, você deverá usar o dataset completo `movies_amostra.csv` **nenhum dado a mais e sem nenhum preprocessamento**. O preprocessamento e geração dos atributos deverá ser feito na própria função (como no exemplo já implementado). Você poderá alterar essa função - até a data de entrega **de seu código**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from competicao_am.gerar_resultado_teste import gerar_saida_teste\n",
    "\n",
    "#altere aqui para o número correspondente ao seu grupo\n",
    "num_grupo = 0 \n",
    "\n",
    "#leia o dataset fornecido pelo professor (coloquei apenas um exemplo, na entrega, será outro)\n",
    "df_amostra_teste = pd.read_csv(\"datasets/movies_amostra_teste_ex.csv\")\n",
    "\n",
    "gerar_saida_teste(df_amostra_teste,\"genero\", num_grupo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprime a saida gerada\n",
    "with open(f\"predict_grupo_{num_grupo}.txt\", \"r\") as file_predict:\n",
    "    for line in file_predict:\n",
    "        print(line,end=\"\")\n",
    "        os.system('cp gera_resultado_av_teste.py {}')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
